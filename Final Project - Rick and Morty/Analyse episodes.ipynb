{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3447406b",
   "metadata": {},
   "source": [
    "## Extract the synopsis and plot of each episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad9f61a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04efe366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(aText):\n",
    "    # remove [[file:<aFile>]]\n",
    "    pattern_file = \"\\[\\[file\\:.*?\\]\\]\"\n",
    "    cleanText = re.sub(pattern_file,'', aText)\n",
    "    # replace then remove [https://<link>]\n",
    "    pattern_url = \"\\[http.*? (.*?)\\]\"\n",
    "    cleanText = re.sub(pattern_url,r'\\1', cleanText)\n",
    "    cleanText = re.sub(\"\\[http.*?\\]\",'',cleanText)\n",
    "    # replace [[<aCharacter>|<infos>]] by <aCharacter>\n",
    "    pattern = \"\\[\\[(.*?)(?:\\|.*?)?\\]\\]\"\n",
    "    cleanText = re.sub(pattern,r\"\\1\", cleanText)\n",
    "    # replace remained [,]\n",
    "    cleanText = cleanText.replace('[','')\n",
    "    cleanText = cleanText.replace(']','')\n",
    "    return cleanText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09417f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_path = 'episode_pages'\n",
    "all_files = [f for f in listdir(pages_path) if isfile(join(pages_path, f))]\n",
    "\n",
    "# for each episode\n",
    "all_descriptions = {}\n",
    "synopsis_header, plot_header = \"==Synopsis==\", \"==Plot==\"\n",
    "\n",
    "for aFile in all_files:\n",
    "    # Read the file containing the episode's page\n",
    "    episode_page = open(pages_path+'/'+aFile, encoding=\"utf-8\").read() \n",
    "    print('Processing... ', aFile)\n",
    "    # Replace if needed synopsis and plot headers\n",
    "    episode_page = re.sub(\"\\=\\= ?Synopsis ?\\=\\=\",\"==Synopsis==\",episode_page)\n",
    "    episode_page = re.sub(\"\\=\\= ?Plot ?\\=\\=\",\"==Plot==\",episode_page)\n",
    "    # Initialize\n",
    "    synopsis, plot = '',''\n",
    "    # Get synopsis and plot if found in page\n",
    "    if synopsis_header in episode_page:\n",
    "        synopsis = episode_page.split(synopsis_header)[1].split('==')[0]\n",
    "        print(\"   Synopsis found\")\n",
    "    if plot_header in episode_page:\n",
    "        plot = episode_page.split(plot_header)[1].split('==')[0]\n",
    "        print(\"   Plot found\")\n",
    "    # Clean synopsis and plot\n",
    "    synopsis, plot = clean_text(synopsis), clean_text(plot)\n",
    "    # Merge both texts\n",
    "    story = synopsis+plot\n",
    "    # Save it locally\n",
    "    # f = codecs.open('episode_stories/'+aFile, \"w+\", \"utf-8\")\n",
    "    # f.write(story)\n",
    "    # f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40f1269",
   "metadata": {},
   "source": [
    "## Tokenization of episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c39ae8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from gensim.parsing.preprocessing import STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "eef7f495",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_path = 'episode_stories'\n",
    "all_files = [f for f in listdir(pages_path) if isfile(join(pages_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "061eac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters = pd.read_csv('RaM_characters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "3d6cd306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the stopwords list in given language\n",
    "stopwords = gensim.parsing.preprocessing.STOPWORDS\n",
    "# tokenization factory\n",
    "tk = WordPunctTokenizer()\n",
    "# lemmatization factory\n",
    "lm = nltk.WordNetLemmatizer()\n",
    "# to exclude\n",
    "specific_words = ['smith','sanchez']\n",
    "\n",
    "# for each episode story\n",
    "for aFile in all_files:\n",
    "    # Read the file containing the character's page description.\n",
    "    episode_page = open(pages_path+'/'+aFile, encoding=\"utf-8\").read() \n",
    "    # Set everything to lower case.\n",
    "    episode_page = episode_page.lower()\n",
    "    # Exclude characters names, BEFORE tokenisation\n",
    "    for aCharacterName in specific_words:\n",
    "        episode_page = episode_page.replace(aCharacterName.lower(),'')\n",
    "    # Tokenize your text\n",
    "    episode_page = tk.tokenize(episode_page)\n",
    "    # Exclude punctuation and stop words\n",
    "    episode_page = [aToken for aToken in episode_page if aToken.isalnum() and aToken not in stopwords]\n",
    "    # Lemmatize words\n",
    "    episode_page = [ lm.lemmatize(w) for w in episode_page ]\n",
    "    # Remove words with less than 2 letters\n",
    "    episode_page = [ w for w in episode_page if len(w)>2]\n",
    "    # Transform list into list separated by spaces\n",
    "    episode_page = ''.join([str(elem)+' ' for elem in episode_page])\n",
    "    # Save your output for future use\n",
    "    f = codecs.open('episode_tokens/'+aFile, \"w+\", \"utf-8\")\n",
    "    f.write(episode_page)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7abb29",
   "metadata": {},
   "source": [
    "# Topic Detection\n",
    "https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7fcd7bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "38f6735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_path = 'episode_tokens'\n",
    "all_files = [f for f in listdir(pages_path) if isfile(join(pages_path, f))]\n",
    "\n",
    "# get the dictionary of tokens for each episode\n",
    "all_tokens = {}\n",
    "\n",
    "# for each episode tokens list\n",
    "for aFile in all_files:\n",
    "    # Read the file containing the tokens of the episode\n",
    "    episode_tokens = open(pages_path+'/'+aFile, encoding=\"utf-8\").read() \n",
    "    all_tokens[aFile]= episode_tokens.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "6d269f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the dictionary id2word by using corpora.Dictionary(YOUR_LIST_OF_LISTS)\n",
    "dictionary = gensim.corpora.Dictionary(all_tokens.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8e4e86bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out tokens that appear in less than 15 documents (absolute number) \n",
    "# or more than 0.5 documents (fraction of total corpus size, not absolute number).\n",
    "dictionary.filter_extremes(no_below=15, no_above=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "70e6305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many words and how many times those words appear = bag of words\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in all_tokens.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "0f3cde61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>rate</th>\n",
       "      <th>nb_votes</th>\n",
       "      <th>imdb_link</th>\n",
       "      <th>Season_nb</th>\n",
       "      <th>Episode_nb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Tales From the Citadel</td>\n",
       "      <td>9.8</td>\n",
       "      <td>29698</td>\n",
       "      <td>https://www.imdb.com/title/tt5218332/</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The Rickshank Rickdemption</td>\n",
       "      <td>9.6</td>\n",
       "      <td>19948</td>\n",
       "      <td>https://www.imdb.com/title/tt5218228/</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Total Rickall</td>\n",
       "      <td>9.6</td>\n",
       "      <td>16633</td>\n",
       "      <td>https://www.imdb.com/title/tt4832262/</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Rickmurai Jack</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8127</td>\n",
       "      <td>https://www.imdb.com/title/tt15041334/</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>The Vat of Acid Episode</td>\n",
       "      <td>9.5</td>\n",
       "      <td>12058</td>\n",
       "      <td>https://www.imdb.com/title/tt10655692/</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank                       Title  rate  nb_votes  \\\n",
       "0     1      Tales From the Citadel   9.8     29698   \n",
       "1     2  The Rickshank Rickdemption   9.6     19948   \n",
       "2     3               Total Rickall   9.6     16633   \n",
       "3     4              Rickmurai Jack   9.5      8127   \n",
       "4     5     The Vat of Acid Episode   9.5     12058   \n",
       "\n",
       "                                imdb_link  Season_nb  Episode_nb  \n",
       "0   https://www.imdb.com/title/tt5218332/          3           7  \n",
       "1   https://www.imdb.com/title/tt5218228/          3           1  \n",
       "2   https://www.imdb.com/title/tt4832262/          2           4  \n",
       "3  https://www.imdb.com/title/tt15041334/          5          10  \n",
       "4  https://www.imdb.com/title/tt10655692/          4           8  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_episodes = pd.read_csv(\"RaM_episodes.csv\")\n",
    "df_ep_ranking = pd.read_csv('RaM_imdb_episodes_ranking.csv')\n",
    "df_ep_ranking.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5b638e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seasonNb_and_episodeNb(aFileEpisodeName):\n",
    "    return int(aFileEpisodeName[1:3]), int(aFileEpisodeName[4:7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "cda79d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top10 words for S01E05 (Meeseeks and Destroy):\n",
      " 'adventure' appears 12 times.\n",
      " 'help' appears 7 times.\n",
      " 'quickly' appears 6 times.\n",
      " 'hand' appears 5 times.\n",
      " 'lead' appears 5 times.\n",
      " 'creature' appears 4 times.\n",
      " 'portal' appears 4 times.\n",
      " 'point' appears 3 times.\n",
      " 'world' appears 3 times.\n",
      " 'having' appears 2 times.\n"
     ]
    }
   ],
   "source": [
    "# get a preview for a chosen episode\n",
    "episode_to_preview = 'S01E05'\n",
    "ep_index = np.argwhere(np.array(all_files)==episode_to_preview+'.txt')[0][0]\n",
    "\n",
    "seasonNb, epNb = get_seasonNb_and_episodeNb(episode_to_preview)\n",
    "ep_title = list(df_episodes[(df_episodes.Season_nb == seasonNb) & (df_episodes.Episode_nb == epNb)].Title)[0]\n",
    "print(\"Top10 words for {} ({}):\".format(episode_to_preview, ep_title))\n",
    "\n",
    "bow_doc_ep = list(sorted(bow_corpus[ep_index], reverse=True, key=lambda x:x[1]))\n",
    "for i in range(10):\n",
    "    print(\" '{}' appears {} times.\".format(\n",
    "        dictionary[bow_doc_ep[i][0]], \n",
    "        bow_doc_ep[i][1])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "eb7b8f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF IDF\n",
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "b34df4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.054*\"planet\" + 0.035*\"adventure\" + 0.032*\"quickly\" + 0.030*\"help\" + 0.029*\"garage\" + 0.021*\"fight\" + 0.021*\"explains\" + 0.017*\"travel\" + 0.017*\"ship\" + 0.016*\"open\"\n",
      "Topic: 1 \n",
      "Words: 0.041*\"planet\" + 0.032*\"people\" + 0.029*\"world\" + 0.027*\"life\" + 0.027*\"ship\" + 0.026*\"car\" + 0.022*\"room\" + 0.022*\"stop\" + 0.021*\"escape\" + 0.021*\"killing\"\n",
      "Topic: 2 \n",
      "Words: 0.034*\"portal\" + 0.029*\"planet\" + 0.026*\"new\" + 0.022*\"gun\" + 0.021*\"going\" + 0.020*\"despite\" + 0.020*\"return\" + 0.020*\"want\" + 0.019*\"free\" + 0.019*\"life\"\n",
      "Topic: 3 \n",
      "Words: 0.039*\"fight\" + 0.036*\"body\" + 0.033*\"idea\" + 0.032*\"world\" + 0.029*\"control\" + 0.029*\"space\" + 0.027*\"head\" + 0.025*\"portal\" + 0.022*\"notice\" + 0.022*\"lead\"\n",
      "Topic: 4 \n",
      "Words: 0.068*\"save\" + 0.055*\"device\" + 0.037*\"head\" + 0.035*\"point\" + 0.028*\"death\" + 0.024*\"planet\" + 0.021*\"appears\" + 0.019*\"instead\" + 0.019*\"new\" + 0.017*\"travel\"\n",
      "Topic: 5 \n",
      "Words: 0.034*\"room\" + 0.031*\"space\" + 0.025*\"know\" + 0.022*\"having\" + 0.020*\"adventure\" + 0.019*\"plan\" + 0.018*\"use\" + 0.017*\"stop\" + 0.016*\"getting\" + 0.016*\"open\"\n",
      "Topic: 6 \n",
      "Words: 0.053*\"planet\" + 0.028*\"dimension\" + 0.028*\"point\" + 0.026*\"house\" + 0.025*\"help\" + 0.025*\"return\" + 0.025*\"creature\" + 0.023*\"portal\" + 0.023*\"death\" + 0.023*\"room\"\n",
      "Topic: 7 \n",
      "Words: 0.060*\"dimension\" + 0.041*\"portal\" + 0.032*\"explains\" + 0.031*\"shoot\" + 0.030*\"gun\" + 0.030*\"house\" + 0.029*\"room\" + 0.024*\"start\" + 0.022*\"having\" + 0.022*\"space\"\n",
      "Topic: 8 \n",
      "Words: 0.038*\"want\" + 0.036*\"new\" + 0.035*\"body\" + 0.028*\"house\" + 0.024*\"car\" + 0.023*\"death\" + 0.021*\"soon\" + 0.020*\"garage\" + 0.020*\"ship\" + 0.019*\"relationship\"\n",
      "Topic: 9 \n",
      "Words: 0.063*\"portal\" + 0.053*\"car\" + 0.030*\"space\" + 0.028*\"gun\" + 0.027*\"shoot\" + 0.022*\"ship\" + 0.022*\"adventure\" + 0.021*\"return\" + 0.021*\"death\" + 0.018*\"telling\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using Bag of Words\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)\n",
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b0ea7dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Word: 0.047*\"creature\" + 0.022*\"relationship\" + 0.021*\"world\" + 0.020*\"dimension\" + 0.017*\"head\" + 0.017*\"place\" + 0.017*\"new\" + 0.017*\"life\" + 0.017*\"device\" + 0.017*\"want\"\n",
      "Topic: 1 \n",
      "Word: 0.060*\"portal\" + 0.047*\"dimension\" + 0.043*\"gun\" + 0.033*\"return\" + 0.021*\"head\" + 0.021*\"house\" + 0.020*\"new\" + 0.019*\"shoot\" + 0.018*\"save\" + 0.015*\"killing\"\n",
      "Topic: 2 \n",
      "Word: 0.058*\"inside\" + 0.028*\"house\" + 0.023*\"making\" + 0.019*\"friend\" + 0.019*\"named\" + 0.019*\"fight\" + 0.018*\"garage\" + 0.018*\"attack\" + 0.018*\"going\" + 0.018*\"car\"\n",
      "Topic: 3 \n",
      "Word: 0.037*\"house\" + 0.034*\"car\" + 0.032*\"body\" + 0.025*\"space\" + 0.023*\"free\" + 0.023*\"talking\" + 0.020*\"look\" + 0.020*\"want\" + 0.018*\"killed\" + 0.018*\"idea\"\n",
      "Topic: 4 \n",
      "Word: 0.036*\"soon\" + 0.030*\"travel\" + 0.029*\"body\" + 0.029*\"death\" + 0.026*\"world\" + 0.023*\"inside\" + 0.020*\"new\" + 0.020*\"adventure\" + 0.019*\"causing\" + 0.017*\"way\"\n",
      "Topic: 5 \n",
      "Word: 0.039*\"planet\" + 0.023*\"ship\" + 0.022*\"open\" + 0.019*\"work\" + 0.017*\"know\" + 0.017*\"people\" + 0.017*\"saying\" + 0.017*\"space\" + 0.016*\"explains\" + 0.016*\"order\"\n",
      "Topic: 6 \n",
      "Word: 0.034*\"car\" + 0.032*\"device\" + 0.030*\"eventually\" + 0.029*\"planet\" + 0.026*\"realizes\" + 0.025*\"telling\" + 0.023*\"portal\" + 0.022*\"later\" + 0.020*\"causing\" + 0.020*\"gun\"\n",
      "Topic: 7 \n",
      "Word: 0.063*\"creature\" + 0.044*\"want\" + 0.018*\"watch\" + 0.017*\"portal\" + 0.017*\"room\" + 0.015*\"left\" + 0.014*\"space\" + 0.013*\"having\" + 0.013*\"body\" + 0.013*\"new\"\n",
      "Topic: 8 \n",
      "Word: 0.024*\"set\" + 0.024*\"watch\" + 0.024*\"world\" + 0.024*\"want\" + 0.023*\"death\" + 0.022*\"dimension\" + 0.022*\"room\" + 0.021*\"having\" + 0.020*\"escape\" + 0.018*\"left\"\n",
      "Topic: 9 \n",
      "Word: 0.022*\"dimension\" + 0.022*\"planet\" + 0.016*\"having\" + 0.016*\"explains\" + 0.015*\"fly\" + 0.014*\"named\" + 0.014*\"later\" + 0.014*\"stop\" + 0.013*\"going\" + 0.013*\"love\"\n"
     ]
    }
   ],
   "source": [
    "# Running LDA using TF-IDF\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)\n",
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} \\nWord: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75114b7",
   "metadata": {},
   "source": [
    "# GePhi animation of characters in function of time (seasons, episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89525b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7bca4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_characters = pd.read_csv('RaM_characters.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c75738d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Hyperlink</th>\n",
       "      <th>Season_nb</th>\n",
       "      <th>Episode_nb</th>\n",
       "      <th>hasTranscript</th>\n",
       "      <th>Involved_Characters</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pilot</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Pilot</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>['Space Cruiser', 'Jessica', 'Summer Smith (Cr...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lawnmower Dog</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Lawnmower...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>['Jerry Smith (Cronenberged dimension)', 'Mrs....</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anatomy Park</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Anatomy_P...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>['Jerry Smith (Cronenberged dimension)', 'Leon...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M. Night Shaym-Aliens!</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/M._Night_...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'Mr. Goldenfol...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meeseeks and Destroy</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Meeseeks_...</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>['Morty Smith', 'Rick Sanchez', 'Mr. Meeseeks'...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Title                                          Hyperlink  \\\n",
       "0                   Pilot         https://rickandmorty.fandom.com/wiki/Pilot   \n",
       "1           Lawnmower Dog  https://rickandmorty.fandom.com/wiki/Lawnmower...   \n",
       "2            Anatomy Park  https://rickandmorty.fandom.com/wiki/Anatomy_P...   \n",
       "3  M. Night Shaym-Aliens!  https://rickandmorty.fandom.com/wiki/M._Night_...   \n",
       "4    Meeseeks and Destroy  https://rickandmorty.fandom.com/wiki/Meeseeks_...   \n",
       "\n",
       "   Season_nb  Episode_nb  hasTranscript  \\\n",
       "0          1           1           True   \n",
       "1          1           2           True   \n",
       "2          1           3           True   \n",
       "3          1           4           True   \n",
       "4          1           5           True   \n",
       "\n",
       "                                 Involved_Characters  Timestamp  \n",
       "0  ['Space Cruiser', 'Jessica', 'Summer Smith (Cr...        1.0  \n",
       "1  ['Jerry Smith (Cronenberged dimension)', 'Mrs....        2.0  \n",
       "2  ['Jerry Smith (Cronenberged dimension)', 'Leon...        3.0  \n",
       "3  ['Rick Sanchez', 'Morty Smith', 'Mr. Goldenfol...        4.0  \n",
       "4  ['Morty Smith', 'Rick Sanchez', 'Mr. Meeseeks'...        5.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_episodes = pd.read_csv('RaM_episodes.csv')\n",
    "df_episodes['Timestamp']=[float(i+1) for i in range (len(df_episodes))]\n",
    "df_episodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1506c5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_timestamps_list_to_intervalles(aList):\n",
    "    return rec_from_timestamps_list_to_intervalles(aList, [], None)\n",
    "\n",
    "def rec_from_timestamps_list_to_intervalles(aList, aResult, ongoing):\n",
    "    \"\"\" aList = list to process / aResult = [[start,end],[uniqueEp],[start,end]] / ongoing = None || (startEp, ongoingEp)\"\"\"\n",
    "    #print(aList, aResult, ongoing)\n",
    "    if aList == []:\n",
    "        # exit case\n",
    "        # add last ongoing\n",
    "        if ongoing != None:\n",
    "            startEp, ongoingEp = ongoing\n",
    "            if startEp == ongoingEp:\n",
    "                aResult.append([startEp])\n",
    "            else:\n",
    "                aResult.append([startEp, ongoingEp])\n",
    "            ongoing = None\n",
    "        return aResult\n",
    "    head, *tail = aList\n",
    "    if ongoing == None:\n",
    "        # we start a new interval\n",
    "        return rec_from_timestamps_list_to_intervalles(tail, aResult, (head, head))\n",
    "    if ongoing != None:\n",
    "        startEp, ongoingEp = ongoing\n",
    "        if head == ongoingEp+1:\n",
    "            # the interval continues\n",
    "            return rec_from_timestamps_list_to_intervalles(tail, aResult, (startEp, head))\n",
    "        # the interval stops\n",
    "        if startEp == ongoingEp:\n",
    "            aResult.append([startEp])\n",
    "        else:\n",
    "            aResult.append([startEp, ongoingEp])\n",
    "        return rec_from_timestamps_list_to_intervalles(tail, aResult, (head,head))\n",
    "\n",
    "assert from_timestamps_list_to_intervalles([1,2,3,5,7,8,9]) == [[1,3],[5],[7,9]]\n",
    "assert from_timestamps_list_to_intervalles([1,2,3,5,7,8,9,11]) == [[1,3],[5],[7,9],[11]]\n",
    "assert from_timestamps_list_to_intervalles([]) == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3aa9842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_ep_intervalles(aListOfIntervalles):\n",
    "    result = []\n",
    "    for element in aListOfIntervalles:\n",
    "        if len(element)==1:\n",
    "            start,end = element[0],element[0]\n",
    "        else:\n",
    "            start,end = element[0],element[1]\n",
    "        result.append([start-0.5, end+0.5])\n",
    "    return result\n",
    "\n",
    "assert update_ep_intervalles([[1,2],[3]]) == [[0.5,2.5],[2.5,3.5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6d4a3441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_intervalles_to_GePhi_string(aListOfTrueIntervalles):\n",
    "    if aListOfTrueIntervalles == []:\n",
    "        return '<[0,0.5]>'\n",
    "    string_result = str(aListOfTrueIntervalles)[1:-1]\n",
    "    return '<'+string_result+'>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7062992c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dict with {character:[list of episodes id]}\n",
    "char_ep_dict = {k:[] for k in df_characters.Name}\n",
    "\n",
    "for _, row in df_episodes.iterrows():\n",
    "    character_in_ep_list = ast.literal_eval(row.Involved_Characters)\n",
    "    for aCharacter in character_in_ep_list:\n",
    "        char_ep_dict[aCharacter].append(row.Timestamp)\n",
    "\n",
    "char_ep_dict = {k:from_timestamps_list_to_intervalles(v) for k,v in char_ep_dict.items()}\n",
    "char_ep_dict = {k:update_ep_intervalles(v) for k,v in char_ep_dict.items()}\n",
    "char_ep_dict = {k:from_intervalles_to_GePhi_string(v) for k,v in char_ep_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "221cfc74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Label</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abandoned Jerrys</td>\n",
       "      <td>Abandoned Jerrys</td>\n",
       "      <td>&lt;[0,0.5]&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abrodolph Lincoler</td>\n",
       "      <td>Abrodolph Lincoler</td>\n",
       "      <td>&lt;[9.5, 11.5], [30.5, 31.5], [35.5, 37.5], [45....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adam</td>\n",
       "      <td>Adam</td>\n",
       "      <td>&lt;[41.5, 42.5]&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adjudicator Rick</td>\n",
       "      <td>Adjudicator Rick</td>\n",
       "      <td>&lt;[27.5, 28.5]&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Afro Rick</td>\n",
       "      <td>Afro Rick</td>\n",
       "      <td>&lt;[21.5, 22.5], [27.5, 28.5]&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Id               Label  \\\n",
       "0    Abandoned Jerrys    Abandoned Jerrys   \n",
       "1  Abrodolph Lincoler  Abrodolph Lincoler   \n",
       "2                Adam                Adam   \n",
       "3    Adjudicator Rick    Adjudicator Rick   \n",
       "4           Afro Rick           Afro Rick   \n",
       "\n",
       "                                            Interval  \n",
       "0                                          <[0,0.5]>  \n",
       "1  <[9.5, 11.5], [30.5, 31.5], [35.5, 37.5], [45....  \n",
       "2                                     <[41.5, 42.5]>  \n",
       "3                                     <[27.5, 28.5]>  \n",
       "4                       <[21.5, 22.5], [27.5, 28.5]>  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gephi_nodes = df_characters[['Name']].copy()\n",
    "df_gephi_nodes = df_gephi_nodes.rename(columns={'Name':'Id'})\n",
    "df_gephi_nodes['Label'] = df_gephi_nodes.Id\n",
    "df_gephi_nodes['Interval'] = char_ep_dict.values()\n",
    "df_gephi_nodes.to_csv('RaM_gephi_nodes_withInterval.csv', index=False)\n",
    "df_gephi_nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b273dd50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Hyperlink</th>\n",
       "      <th>Season_nb</th>\n",
       "      <th>Episode_nb</th>\n",
       "      <th>hasTranscript</th>\n",
       "      <th>Involved_Characters</th>\n",
       "      <th>Timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Mort Dinner Rick Andre</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Mort_Dinn...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'Summer Smith'...</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Mortyplicity</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Mortyplicity</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'Summer Smith'...</td>\n",
       "      <td>43.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>A Rickconvenient Mort</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/A_Rickcon...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'Diesel Weasel...</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Rickdependence Spray</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Rickdepen...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>['The President', 'Professor Shabooboo', 'Stic...</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Amortycan Grickfitti</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Amortycan...</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>['Beth Smith', 'Jerry Smith', 'Morty Smith', '...</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Rick &amp; Morty's Thanksploitation Spectacular</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Rick_%26_...</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'The President...</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Gotron Jerrysis Rickvangelion</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Gotron_Je...</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>['Rick Sanchez', 'Summer Smith', 'Morty Smith'...</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Rickternal Friendshine of the Spotless Mort</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Rickterna...</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>False</td>\n",
       "      <td>['Rick Sanchez', 'The Garage', 'Birdperson', '...</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Forgetting Sarick Mortshall</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Forgettin...</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "      <td>['Morty Smith', 'Rick Sanchez', 'Nick', 'Summe...</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Rickmurai Jack</td>\n",
       "      <td>https://rickandmorty.fandom.com/wiki/Rickmurai...</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>['Rick Sanchez', 'Morty Smith', 'Jerry Smith',...</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Title  \\\n",
       "41                       Mort Dinner Rick Andre   \n",
       "42                                 Mortyplicity   \n",
       "43                        A Rickconvenient Mort   \n",
       "44                         Rickdependence Spray   \n",
       "45                         Amortycan Grickfitti   \n",
       "46  Rick & Morty's Thanksploitation Spectacular   \n",
       "47                Gotron Jerrysis Rickvangelion   \n",
       "48  Rickternal Friendshine of the Spotless Mort   \n",
       "49                  Forgetting Sarick Mortshall   \n",
       "50                               Rickmurai Jack   \n",
       "\n",
       "                                            Hyperlink  Season_nb  Episode_nb  \\\n",
       "41  https://rickandmorty.fandom.com/wiki/Mort_Dinn...          5           1   \n",
       "42  https://rickandmorty.fandom.com/wiki/Mortyplicity          5           2   \n",
       "43  https://rickandmorty.fandom.com/wiki/A_Rickcon...          5           3   \n",
       "44  https://rickandmorty.fandom.com/wiki/Rickdepen...          5           4   \n",
       "45  https://rickandmorty.fandom.com/wiki/Amortycan...          5           5   \n",
       "46  https://rickandmorty.fandom.com/wiki/Rick_%26_...          5           6   \n",
       "47  https://rickandmorty.fandom.com/wiki/Gotron_Je...          5           7   \n",
       "48  https://rickandmorty.fandom.com/wiki/Rickterna...          5           8   \n",
       "49  https://rickandmorty.fandom.com/wiki/Forgettin...          5           9   \n",
       "50  https://rickandmorty.fandom.com/wiki/Rickmurai...          5          10   \n",
       "\n",
       "    hasTranscript                                Involved_Characters  \\\n",
       "41          False  ['Rick Sanchez', 'Morty Smith', 'Summer Smith'...   \n",
       "42           True  ['Rick Sanchez', 'Morty Smith', 'Summer Smith'...   \n",
       "43          False  ['Rick Sanchez', 'Morty Smith', 'Diesel Weasel...   \n",
       "44          False  ['The President', 'Professor Shabooboo', 'Stic...   \n",
       "45          False  ['Beth Smith', 'Jerry Smith', 'Morty Smith', '...   \n",
       "46          False  ['Rick Sanchez', 'Morty Smith', 'The President...   \n",
       "47          False  ['Rick Sanchez', 'Summer Smith', 'Morty Smith'...   \n",
       "48          False  ['Rick Sanchez', 'The Garage', 'Birdperson', '...   \n",
       "49          False  ['Morty Smith', 'Rick Sanchez', 'Nick', 'Summe...   \n",
       "50           True  ['Rick Sanchez', 'Morty Smith', 'Jerry Smith',...   \n",
       "\n",
       "    Timestamp  \n",
       "41       42.0  \n",
       "42       43.0  \n",
       "43       44.0  \n",
       "44       45.0  \n",
       "45       46.0  \n",
       "46       47.0  \n",
       "47       48.0  \n",
       "48       49.0  \n",
       "49       50.0  \n",
       "50       51.0  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_episodes[df_episodes.Season_nb==5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857205db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
